# Question Pro - Seq2Seq

## Introduction
The Seq2Seq model in QuestionPro utilizes a robust sequence-to-sequence architecture to generate questions from provided contexts. This model, rooted in deep learning and natural language processing, excels at understanding and transforming input sequences into meaningful output sequences.

With Seq2Seq, the task of question generation becomes dynamic and context-aware. The model can capture intricate relationships within a context and translate them into well-structured questions. By leveraging the inherent sequential nature of language, Seq2Seq enhances the precision and relevance of the generated questions.

## Dataset and Model
- Stanford Question Answering Dataset [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/)
- Model and Vocab: [Dropbox](https://www.dropbox.com/scl/fo/06z72prw84qvdon24zve7/h?rlkey=92nr17ygw0ghhuies0qwgavvp&dl=0)

## Requirements
- Language: Python3.8
- Packages
  -  torch: 1.5.0
  -  spacy: 2.2.4
  -  torchtext: 0.3.1

## Preprocessing Steps

- Case Normalization: Convert all text to lowercase or uppercase to ensure uniformity.
- Tokenization: Break text into individual tokens (words or subword units) to facilitate processing.
- Named Entity Recognition (NER): Identify and classify entities (e.g., names, locations) within the text.
- POS-Tagging (Part-of-Speech Tagging): Assign grammatical parts of speech to each token in the text.
- IOB-Tagging (Inside-Outside-Beginning Tagging): Label tokens with Inside, Outside, or Beginning tags to represent entities sequentially.
- Pairing Input and Output: Organize the preprocessed data into input-output pairs for training the Seq2Seq model.

These preprocessing steps lay the foundation for training a powerful Seq2Seq model by ensuring the input data is appropriately formatted and enriched with linguistic information. Each step is crucial in preparing the data for effective sequence-to-sequence processing.

## Model Architecture
The Seq2Seq (Sequence-to-Sequence) model employed in this project is designed to convert input sequences into output sequences, making it particularly effective for tasks like question generation. Below is an overview of the key components of the Seq2Seq model architecture.

### Encoder
The encoder is responsible for processing the input sequence and capturing its contextual information. It converts the input sequence into a fixed-size context vector, the foundation for generating the output sequence.

### Decoder
The decoder takes the context vector generated by the encoder and uses it to produce the output sequence. It does so step-by-step, generating one token at a time while considering the previously generated tokens. This process continues until the entire output sequence is produced.

### Attention Mechanism
An attention mechanism enhances the model's ability to capture relevant information from the input sequence during decoding. This allows the model to focus on different parts of the input sequence at different decoding steps, improving its overall performance.

### Training
The Seq2Seq model is trained using pairs of input and target sequences. The training involves optimizing the model's parameters to minimize the difference between the predicted output and the target sequence.

This model architecture provides a robust framework for sequence-to-sequence tasks, offering flexibility and effectiveness in various natural language processing applications.

## How to Run the project

### Download SQuAD dataset
```shell
  python main.py --directory [DIRECTORY]
```

### Squad Parse
```shell
python squad_parse.py --train_filepath [PATH TO TRAIN JSON] --dev_filepath [PATH TO DEV JSON] --save [DIRECTORY TO STORE RESULT]
```

### Train
```shell
python train.py --train-set [PATH TO THE PREPROCESSED TRAIN CSV] --dev-set [PATH TO THE PREPROCESSED DEV CSV] --epochs 100  --save [DIRECTORY TO STORE RESULT] --batch-size 128 --save [DIRECTORY TO STORE RESULT]
```
Or
Run train_test.ipynb

### Evaluate
Run evaluate_model.ipynb

## API test

```
/seq2seq
{
  "context": " ",
  "answer": " ",
  }
```
